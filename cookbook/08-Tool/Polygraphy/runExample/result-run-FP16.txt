[V] Loaded Module: polygraphy.util    | Path: ['/usr/local/lib/python3.8/dist-packages/polygraphy/util']
[V] Model: model.onnx
[V] Loaded Module: polygraphy         | Version: 0.36.2 | Path: ['/usr/local/lib/python3.8/dist-packages/polygraphy']
[I] Will generate inference input data according to provided TensorMetadata: {tensor-0 [shape=(4, 1, 28, 28)]}
[I] onnxrt-runner-N0-06/15/22-04:23:28  | Activating and starting inference
[V] Loaded Module: onnxruntime        | Version: 1.11.1 | Path: ['/usr/local/lib/python3.8/dist-packages/onnxruntime']
[I] Creating ONNX-Runtime Inference Session with providers: ['CPUExecutionProvider']
[V] Loaded Module: numpy              | Version: 1.22.3 | Path: ['/usr/local/lib/python3.8/dist-packages/numpy']
[V] Loading inputs from data loader
[V] Generating data using numpy seed: 1
[V] Input tensor: tensor-0 | Generating input data in range: [0.0, 1.0]
[I] onnxrt-runner-N0-06/15/22-04:23:28 
    ---- Inference Input(s) ----
    {tensor-0 [dtype=float32, shape=(4, 1, 28, 28)]}
[V] Runner input metadata is: {tensor-0 [dtype=float32, shape=('B', 1, 28, 28)]}
[I] onnxrt-runner-N0-06/15/22-04:23:28 
    ---- Inference Output(s) ----
    {tensor-15 [dtype=int64, shape=(4,)]}
[I] onnxrt-runner-N0-06/15/22-04:23:28  | Completed 1 iteration(s) in 0.8748 ms | Average inference time: 0.8748 ms.
[I] trt-runner-N0-06/15/22-04:23:28     | Activating and starting inference
