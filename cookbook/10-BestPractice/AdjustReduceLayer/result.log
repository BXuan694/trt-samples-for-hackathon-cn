&&&& RUNNING TensorRT.trtexec [TensorRT v8401] # trtexec --onnx=model-0.onnx --verbose --useCudaGraph --noDataTransfers --minShapes=tensor0:1x256x1024 --optShapes=tensor0:1x256x1024 --maxShapes=tensor0:1x256x1024 --shapes=tensor0:1x256x1024
[09/07/2022-04:03:43] [I] === Model Options ===
[09/07/2022-04:03:43] [I] Format: ONNX
[09/07/2022-04:03:43] [I] Model: model-0.onnx
[09/07/2022-04:03:43] [I] Output:
[09/07/2022-04:03:43] [I] === Build Options ===
[09/07/2022-04:03:43] [I] Max batch: explicit batch
[09/07/2022-04:03:43] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[09/07/2022-04:03:43] [I] minTiming: 1
[09/07/2022-04:03:43] [I] avgTiming: 8
[09/07/2022-04:03:43] [I] Precision: FP32
[09/07/2022-04:03:43] [I] LayerPrecisions: 
[09/07/2022-04:03:43] [I] Calibration: 
[09/07/2022-04:03:43] [I] Refit: Disabled
[09/07/2022-04:03:43] [I] Sparsity: Disabled
[09/07/2022-04:03:43] [I] Safe mode: Disabled
[09/07/2022-04:03:43] [I] DirectIO mode: Disabled
[09/07/2022-04:03:43] [I] Restricted mode: Disabled
[09/07/2022-04:03:43] [I] Build only: Disabled
[09/07/2022-04:03:43] [I] Save engine: 
[09/07/2022-04:03:43] [I] Load engine: 
[09/07/2022-04:03:43] [I] Profiling verbosity: 0
[09/07/2022-04:03:43] [I] Tactic sources: Using default tactic sources
[09/07/2022-04:03:43] [I] timingCacheMode: local
[09/07/2022-04:03:43] [I] timingCacheFile: 
[09/07/2022-04:03:43] [I] Input(s)s format: fp32:CHW
[09/07/2022-04:03:43] [I] Output(s)s format: fp32:CHW
[09/07/2022-04:03:43] [I] Input build shape: tensor0=1x256x1024+1x256x1024+1x256x1024
[09/07/2022-04:03:43] [I] Input calibration shapes: model
[09/07/2022-04:03:43] [I] === System Options ===
[09/07/2022-04:03:43] [I] Device: 0
[09/07/2022-04:03:43] [I] DLACore: 
[09/07/2022-04:03:43] [I] Plugins:
[09/07/2022-04:03:43] [I] === Inference Options ===
[09/07/2022-04:03:43] [I] Batch: Explicit
[09/07/2022-04:03:43] [I] Input inference shape: tensor0=1x256x1024
[09/07/2022-04:03:43] [I] Iterations: 10
[09/07/2022-04:03:43] [I] Duration: 3s (+ 200ms warm up)
[09/07/2022-04:03:43] [I] Sleep time: 0ms
[09/07/2022-04:03:43] [I] Idle time: 0ms
[09/07/2022-04:03:43] [I] Streams: 1
[09/07/2022-04:03:43] [I] ExposeDMA: Disabled
[09/07/2022-04:03:43] [I] Data transfers: Disabled
[09/07/2022-04:03:43] [I] Spin-wait: Disabled
[09/07/2022-04:03:43] [I] Multithreading: Disabled
[09/07/2022-04:03:43] [I] CUDA Graph: Enabled
[09/07/2022-04:03:43] [I] Separate profiling: Disabled
[09/07/2022-04:03:43] [I] Time Deserialize: Disabled
[09/07/2022-04:03:43] [I] Time Refit: Disabled
[09/07/2022-04:03:43] [I] Inputs:
[09/07/2022-04:03:43] [I] === Reporting Options ===
[09/07/2022-04:03:43] [I] Verbose: Enabled
[09/07/2022-04:03:43] [I] Averages: 10 inferences
[09/07/2022-04:03:43] [I] Percentile: 99
[09/07/2022-04:03:43] [I] Dump refittable layers:Disabled
[09/07/2022-04:03:43] [I] Dump output: Disabled
[09/07/2022-04:03:43] [I] Profile: Disabled
[09/07/2022-04:03:43] [I] Export timing to JSON file: 
[09/07/2022-04:03:43] [I] Export output to JSON file: 
[09/07/2022-04:03:43] [I] Export profile to JSON file: 
[09/07/2022-04:03:43] [I] 
[09/07/2022-04:03:43] [I] === Device Information ===
[09/07/2022-04:03:43] [I] Selected Device: NVIDIA GeForce GTX 1070
[09/07/2022-04:03:43] [I] Compute Capability: 6.1
[09/07/2022-04:03:43] [I] SMs: 16
[09/07/2022-04:03:43] [I] Compute Clock Rate: 1.645 GHz
[09/07/2022-04:03:43] [I] Device Global Memory: 8111 MiB
[09/07/2022-04:03:43] [I] Shared Memory per SM: 96 KiB
[09/07/2022-04:03:43] [I] Memory Bus Width: 256 bits (ECC disabled)
[09/07/2022-04:03:43] [I] Memory Clock Rate: 4.004 GHz
[09/07/2022-04:03:43] [I] 
[09/07/2022-04:03:43] [I] TensorRT version: 8.4.1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::Proposal version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::Split version 1
[09/07/2022-04:03:43] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[09/07/2022-04:03:43] [I] [TRT] [MemUsageChange] Init CUDA: CPU +194, GPU +0, now: CPU 202, GPU 425 (MiB)
[09/07/2022-04:03:44] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +6, GPU +2, now: CPU 228, GPU 427 (MiB)
[09/07/2022-04:03:44] [I] Start parsing network model
[09/07/2022-04:03:44] [I] [TRT] ----------------------------------------------------------------
[09/07/2022-04:03:44] [I] [TRT] Input filename:   model-0.onnx
[09/07/2022-04:03:44] [I] [TRT] ONNX IR version:  0.0.8
[09/07/2022-04:03:44] [I] [TRT] Opset version:    13
[09/07/2022-04:03:44] [I] [TRT] Producer name:    
[09/07/2022-04:03:44] [I] [TRT] Producer version: 
[09/07/2022-04:03:44] [I] [TRT] Domain:           
[09/07/2022-04:03:44] [I] [TRT] Model version:    0
[09/07/2022-04:03:44] [I] [TRT] Doc string:       
[09/07/2022-04:03:44] [I] [TRT] ----------------------------------------------------------------
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::Split version 1
[09/07/2022-04:03:44] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[09/07/2022-04:03:44] [V] [TRT] Adding network input: tensor0 with dtype: float32, dimensions: (-1, 256, -1)
[09/07/2022-04:03:44] [V] [TRT] Registering tensor: tensor0 for ONNX tensor: tensor0
[09/07/2022-04:03:44] [V] [TRT] Importing initializer: constantM2
[09/07/2022-04:03:44] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:367: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[09/07/2022-04:03:44] [V] [TRT] Parsing node: ReduceSum [ReduceSum]
[09/07/2022-04:03:44] [V] [TRT] Searching for input: tensor0
[09/07/2022-04:03:44] [V] [TRT] Searching for input: constantM2
[09/07/2022-04:03:44] [V] [TRT] ReduceSum [ReduceSum] inputs: [tensor0 -> (-1, 256, -1)[FLOAT]], [constantM2 -> (1)[INT32]], 
[09/07/2022-04:03:44] [V] [TRT] Registering layer: ReduceSum for ONNX node: ReduceSum
[09/07/2022-04:03:44] [V] [TRT] Registering tensor: tensor1_0 for ONNX tensor: tensor1
[09/07/2022-04:03:44] [V] [TRT] ReduceSum [ReduceSum] outputs: [tensor1 -> (-1, 1, -1)[FLOAT]], 
[09/07/2022-04:03:44] [V] [TRT] Marking tensor1_0 as output: tensor1
[09/07/2022-04:03:44] [I] Finish parsing network model
[09/07/2022-04:03:44] [V] [TRT] Applying generic optimizations to the graph for inference.
[09/07/2022-04:03:44] [V] [TRT] Original: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After dead-layer removal: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After Myelin optimization: 1 layers
[09/07/2022-04:03:44] [V] [TRT] Applying ScaleNodes fusions.
[09/07/2022-04:03:44] [V] [TRT] After scale fusion: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After dupe layer removal: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After final dead-layer removal: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After tensor merging: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After vertical fusions: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After dupe layer removal: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After final dead-layer removal: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After tensor merging: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After slice removal: 1 layers
[09/07/2022-04:03:44] [V] [TRT] After concat removal: 1 layers
[09/07/2022-04:03:44] [V] [TRT] Trying to split Reshape and strided tensor
[09/07/2022-04:03:44] [V] [TRT] Graph construction and optimization completed in 0.000654088 seconds.
[09/07/2022-04:03:44] [V] [TRT] Using cublas as a tactic source
[09/07/2022-04:03:44] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +255, GPU +106, now: CPU 493, GPU 537 (MiB)
[09/07/2022-04:03:44] [V] [TRT] Using cuDNN as a tactic source
[09/07/2022-04:03:44] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +114, GPU +46, now: CPU 607, GPU 583 (MiB)
[09/07/2022-04:03:44] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[09/07/2022-04:03:44] [V] [TRT] Constructing optimization profile number 0 [1/1].
[09/07/2022-04:03:44] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[09/07/2022-04:03:44] [V] [TRT] =============== Computing reformatting costs
[09/07/2022-04:03:44] [V] [TRT] =============== Computing reformatting costs
[09/07/2022-04:03:44] [V] [TRT] =============== Computing costs for 
[09/07/2022-04:03:44] [V] [TRT] *************** Autotuning format combination: Float(262144,1024,1) -> Float(1024,1024,1) ***************
[09/07/2022-04:03:44] [V] [TRT] --------------- Timing Runner: ReduceSum (Reduce)
[09/07/2022-04:03:44] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0210651
[09/07/2022-04:03:44] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0211063
[09/07/2022-04:03:44] [V] [TRT] Fastest Tactic: 0x0000000000000007 Time: 0.0210651
[09/07/2022-04:03:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000007
[09/07/2022-04:03:44] [V] [TRT] Formats and tactics selection completed in 0.00452209 seconds.
[09/07/2022-04:03:44] [V] [TRT] After reformat layers: 1 layers
[09/07/2022-04:03:44] [V] [TRT] Pre-optimized block assignment.
[09/07/2022-04:03:44] [V] [TRT] Block size 8505196544
[09/07/2022-04:03:44] [V] [TRT] Total Activation Memory: 8505196544
[09/07/2022-04:03:44] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[09/07/2022-04:03:44] [V] [TRT] Layer: ReduceSum Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[09/07/2022-04:03:44] [I] [TRT] Total Host Persistent Memory: 0
[09/07/2022-04:03:44] [I] [TRT] Total Device Persistent Memory: 0
[09/07/2022-04:03:44] [I] [TRT] Total Scratch Memory: 0
[09/07/2022-04:03:44] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 4 MiB
[09/07/2022-04:03:44] [V] [TRT] Optimized block assignment.
[09/07/2022-04:03:44] [I] [TRT] Total Activation Memory: 0
[09/07/2022-04:03:44] [V] [TRT] Disabling unused tactic source: CUDNN
[09/07/2022-04:03:44] [V] [TRT] Disabling unused tactic source: CUBLAS, CUBLAS_LT
[09/07/2022-04:03:44] [V] [TRT] Disabling unused tactic source: EDGE_MASK_CONVOLUTIONS
[09/07/2022-04:03:44] [V] [TRT] Engine generation completed in 0.306417 seconds.
[09/07/2022-04:03:44] [V] [TRT] Engine Layer Information:
Layer(Reduce): ReduceSum, Tactic: 0x0000000000000007, tensor0[Float(1,256,1024)] -> tensor1[Float(1,1,1024)]
[09/07/2022-04:03:44] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[09/07/2022-04:03:44] [W] [TRT] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
[09/07/2022-04:03:44] [W] [TRT] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
[09/07/2022-04:03:44] [I] Engine built in 1.11192 sec.
[09/07/2022-04:03:44] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 601, GPU 565 (MiB)
[09/07/2022-04:03:44] [I] [TRT] Loaded engine size: 0 MiB
[09/07/2022-04:03:44] [V] [TRT] Deserialization required 288 microseconds.
[09/07/2022-04:03:44] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[09/07/2022-04:03:44] [I] Engine deserialized in 0.000539817 sec.
[09/07/2022-04:03:44] [V] [TRT] Total per-runner device persistent memory is 0
[09/07/2022-04:03:44] [V] [TRT] Total per-runner host persistent memory is 0
[09/07/2022-04:03:44] [V] [TRT] Allocated activation device memory of size 0
[09/07/2022-04:03:44] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[09/07/2022-04:03:44] [I] Using random values for input tensor0
[09/07/2022-04:03:44] [I] Created input binding for tensor0 with dimensions 1x256x1024
[09/07/2022-04:03:44] [I] Using random values for output tensor1
[09/07/2022-04:03:44] [I] Created output binding for tensor1 with dimensions 1x1x1024
[09/07/2022-04:03:44] [I] Starting inference
[09/07/2022-04:03:47] [I] Warmup completed 8727 queries over 200 ms
[09/07/2022-04:03:47] [I] Timing trace has 159495 queries over 3.00003 s
[09/07/2022-04:03:47] [I] 
[09/07/2022-04:03:47] [I] === Trace details ===
[09/07/2022-04:03:47] [I] Trace averages of 10 runs:
[09/07/2022-04:03:47] [I] 
[09/07/2022-04:03:47] [I] === Performance summary ===
[09/07/2022-04:03:47] [I] Throughput: 53164.4 qps
[09/07/2022-04:03:47] [I] Latency: min = 0.0163574 ms, max = 0.134155 ms, mean = 0.017295 ms, median = 0.017334 ms, percentile(99%) = 0.0196075 ms
[09/07/2022-04:03:47] [I] Enqueue Time: min = 0.000732422 ms, max = 0.0199585 ms, mean = 0.00107462 ms, median = 0.000976562 ms, percentile(99%) = 0.0017395 ms
[09/07/2022-04:03:47] [I] H2D Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(99%) = 0 ms
[09/07/2022-04:03:47] [I] GPU Compute Time: min = 0.0163574 ms, max = 0.134155 ms, mean = 0.017295 ms, median = 0.017334 ms, percentile(99%) = 0.0196075 ms
[09/07/2022-04:03:47] [I] D2H Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(99%) = 0 ms
[09/07/2022-04:03:47] [I] Total Host Walltime: 3.00003 s
[09/07/2022-04:03:47] [I] Total GPU Compute Time: 2.75847 s
[09/07/2022-04:03:47] [W] * GPU compute time is unstable, with coefficient of variance = 5.0829%.
[09/07/2022-04:03:47] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.
[09/07/2022-04:03:47] [I] Explanations of the performance metrics are printed in the verbose logs.
[09/07/2022-04:03:47] [V] 
[09/07/2022-04:03:47] [V] === Explanations of the performance metrics ===
[09/07/2022-04:03:47] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[09/07/2022-04:03:47] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[09/07/2022-04:03:47] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[09/07/2022-04:03:47] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[09/07/2022-04:03:47] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[09/07/2022-04:03:47] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[09/07/2022-04:03:47] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[09/07/2022-04:03:47] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[09/07/2022-04:03:47] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8401] # trtexec --onnx=model-0.onnx --verbose --useCudaGraph --noDataTransfers --minShapes=tensor0:1x256x1024 --optShapes=tensor0:1x256x1024 --maxShapes=tensor0:1x256x1024 --shapes=tensor0:1x256x1024
&&&& RUNNING TensorRT.trtexec [TensorRT v8401] # trtexec --onnx=model-1.onnx --verbose --useCudaGraph --noDataTransfers --minShapes=tensor0:1x256x1024 --optShapes=tensor0:1x256x1024 --maxShapes=tensor0:1x256x1024 --shapes=tensor0:1x256x1024
[09/07/2022-04:03:47] [I] === Model Options ===
[09/07/2022-04:03:47] [I] Format: ONNX
[09/07/2022-04:03:47] [I] Model: model-1.onnx
[09/07/2022-04:03:47] [I] Output:
[09/07/2022-04:03:47] [I] === Build Options ===
[09/07/2022-04:03:47] [I] Max batch: explicit batch
[09/07/2022-04:03:47] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[09/07/2022-04:03:47] [I] minTiming: 1
[09/07/2022-04:03:47] [I] avgTiming: 8
[09/07/2022-04:03:47] [I] Precision: FP32
[09/07/2022-04:03:47] [I] LayerPrecisions: 
[09/07/2022-04:03:47] [I] Calibration: 
[09/07/2022-04:03:47] [I] Refit: Disabled
[09/07/2022-04:03:47] [I] Sparsity: Disabled
[09/07/2022-04:03:47] [I] Safe mode: Disabled
[09/07/2022-04:03:47] [I] DirectIO mode: Disabled
[09/07/2022-04:03:47] [I] Restricted mode: Disabled
[09/07/2022-04:03:47] [I] Build only: Disabled
[09/07/2022-04:03:47] [I] Save engine: 
[09/07/2022-04:03:47] [I] Load engine: 
[09/07/2022-04:03:47] [I] Profiling verbosity: 0
[09/07/2022-04:03:47] [I] Tactic sources: Using default tactic sources
[09/07/2022-04:03:47] [I] timingCacheMode: local
[09/07/2022-04:03:47] [I] timingCacheFile: 
[09/07/2022-04:03:47] [I] Input(s)s format: fp32:CHW
[09/07/2022-04:03:47] [I] Output(s)s format: fp32:CHW
[09/07/2022-04:03:47] [I] Input build shape: tensor0=1x256x1024+1x256x1024+1x256x1024
[09/07/2022-04:03:47] [I] Input calibration shapes: model
[09/07/2022-04:03:47] [I] === System Options ===
[09/07/2022-04:03:47] [I] Device: 0
[09/07/2022-04:03:47] [I] DLACore: 
[09/07/2022-04:03:47] [I] Plugins:
[09/07/2022-04:03:47] [I] === Inference Options ===
[09/07/2022-04:03:47] [I] Batch: Explicit
[09/07/2022-04:03:47] [I] Input inference shape: tensor0=1x256x1024
[09/07/2022-04:03:47] [I] Iterations: 10
[09/07/2022-04:03:47] [I] Duration: 3s (+ 200ms warm up)
[09/07/2022-04:03:47] [I] Sleep time: 0ms
[09/07/2022-04:03:47] [I] Idle time: 0ms
[09/07/2022-04:03:47] [I] Streams: 1
[09/07/2022-04:03:47] [I] ExposeDMA: Disabled
[09/07/2022-04:03:47] [I] Data transfers: Disabled
[09/07/2022-04:03:47] [I] Spin-wait: Disabled
[09/07/2022-04:03:47] [I] Multithreading: Disabled
[09/07/2022-04:03:47] [I] CUDA Graph: Enabled
[09/07/2022-04:03:47] [I] Separate profiling: Disabled
[09/07/2022-04:03:47] [I] Time Deserialize: Disabled
[09/07/2022-04:03:47] [I] Time Refit: Disabled
[09/07/2022-04:03:47] [I] Inputs:
[09/07/2022-04:03:47] [I] === Reporting Options ===
[09/07/2022-04:03:47] [I] Verbose: Enabled
[09/07/2022-04:03:47] [I] Averages: 10 inferences
[09/07/2022-04:03:47] [I] Percentile: 99
[09/07/2022-04:03:47] [I] Dump refittable layers:Disabled
[09/07/2022-04:03:47] [I] Dump output: Disabled
[09/07/2022-04:03:47] [I] Profile: Disabled
[09/07/2022-04:03:47] [I] Export timing to JSON file: 
[09/07/2022-04:03:47] [I] Export output to JSON file: 
[09/07/2022-04:03:47] [I] Export profile to JSON file: 
[09/07/2022-04:03:47] [I] 
[09/07/2022-04:03:47] [I] === Device Information ===
[09/07/2022-04:03:47] [I] Selected Device: NVIDIA GeForce GTX 1070
[09/07/2022-04:03:47] [I] Compute Capability: 6.1
[09/07/2022-04:03:47] [I] SMs: 16
[09/07/2022-04:03:47] [I] Compute Clock Rate: 1.645 GHz
[09/07/2022-04:03:47] [I] Device Global Memory: 8111 MiB
[09/07/2022-04:03:47] [I] Shared Memory per SM: 96 KiB
[09/07/2022-04:03:47] [I] Memory Bus Width: 256 bits (ECC disabled)
[09/07/2022-04:03:47] [I] Memory Clock Rate: 4.004 GHz
[09/07/2022-04:03:47] [I] 
[09/07/2022-04:03:47] [I] TensorRT version: 8.4.1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::Proposal version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::Split version 1
[09/07/2022-04:03:47] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[09/07/2022-04:03:48] [I] [TRT] [MemUsageChange] Init CUDA: CPU +194, GPU +0, now: CPU 202, GPU 425 (MiB)
[09/07/2022-04:03:48] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +6, GPU +2, now: CPU 228, GPU 427 (MiB)
[09/07/2022-04:03:48] [I] Start parsing network model
[09/07/2022-04:03:48] [I] [TRT] ----------------------------------------------------------------
[09/07/2022-04:03:48] [I] [TRT] Input filename:   model-1.onnx
[09/07/2022-04:03:48] [I] [TRT] ONNX IR version:  0.0.8
[09/07/2022-04:03:48] [I] [TRT] Opset version:    13
[09/07/2022-04:03:48] [I] [TRT] Producer name:    
[09/07/2022-04:03:48] [I] [TRT] Producer version: 
[09/07/2022-04:03:48] [I] [TRT] Domain:           
[09/07/2022-04:03:48] [I] [TRT] Model version:    0
[09/07/2022-04:03:48] [I] [TRT] Doc string:       
[09/07/2022-04:03:48] [I] [TRT] ----------------------------------------------------------------
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::Split version 1
[09/07/2022-04:03:48] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[09/07/2022-04:03:48] [V] [TRT] Adding network input: tensor0 with dtype: float32, dimensions: (-1, 256, -1)
[09/07/2022-04:03:48] [V] [TRT] Registering tensor: tensor0 for ONNX tensor: tensor0
[09/07/2022-04:03:48] [V] [TRT] Importing initializer: constantM1
[09/07/2022-04:03:48] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:367: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[09/07/2022-04:03:48] [V] [TRT] Parsing node: Transpose-0 [Transpose]
[09/07/2022-04:03:48] [V] [TRT] Searching for input: tensor0
[09/07/2022-04:03:48] [V] [TRT] Transpose-0 [Transpose] inputs: [tensor0 -> (-1, 256, -1)[FLOAT]], 
[09/07/2022-04:03:48] [V] [TRT] Registering layer: Transpose-0 for ONNX node: Transpose-0
[09/07/2022-04:03:48] [V] [TRT] Registering tensor: tensor2 for ONNX tensor: tensor2
[09/07/2022-04:03:48] [V] [TRT] Transpose-0 [Transpose] outputs: [tensor2 -> (-1, -1, 256)[FLOAT]], 
[09/07/2022-04:03:48] [V] [TRT] Parsing node: ReduceSum [ReduceSum]
[09/07/2022-04:03:48] [V] [TRT] Searching for input: tensor2
[09/07/2022-04:03:48] [V] [TRT] Searching for input: constantM1
[09/07/2022-04:03:48] [V] [TRT] ReduceSum [ReduceSum] inputs: [tensor2 -> (-1, -1, 256)[FLOAT]], [constantM1 -> (1)[INT32]], 
[09/07/2022-04:03:48] [V] [TRT] Registering layer: ReduceSum for ONNX node: ReduceSum
[09/07/2022-04:03:48] [V] [TRT] Registering tensor: tensor3 for ONNX tensor: tensor3
[09/07/2022-04:03:48] [V] [TRT] ReduceSum [ReduceSum] outputs: [tensor3 -> (-1, -1, 1)[FLOAT]], 
[09/07/2022-04:03:48] [V] [TRT] Parsing node: Transpose-1 [Transpose]
[09/07/2022-04:03:48] [V] [TRT] Searching for input: tensor3
[09/07/2022-04:03:48] [V] [TRT] Transpose-1 [Transpose] inputs: [tensor3 -> (-1, -1, 1)[FLOAT]], 
[09/07/2022-04:03:48] [V] [TRT] Registering layer: Transpose-1 for ONNX node: Transpose-1
[09/07/2022-04:03:48] [V] [TRT] Registering tensor: tensor1_0 for ONNX tensor: tensor1
[09/07/2022-04:03:48] [V] [TRT] Transpose-1 [Transpose] outputs: [tensor1 -> (-1, 1, -1)[FLOAT]], 
[09/07/2022-04:03:48] [V] [TRT] Marking tensor1_0 as output: tensor1
[09/07/2022-04:03:48] [I] Finish parsing network model
[09/07/2022-04:03:48] [V] [TRT] Applying generic optimizations to the graph for inference.
[09/07/2022-04:03:48] [V] [TRT] Original: 3 layers
[09/07/2022-04:03:48] [V] [TRT] After dead-layer removal: 3 layers
[09/07/2022-04:03:48] [V] [TRT] Running: ShuffleReduceSwap on Transpose-0
[09/07/2022-04:03:48] [V] [TRT] Swapping Transpose-0 with ReduceSum
[09/07/2022-04:03:48] [V] [TRT] Running: ShuffleShuffleFusion on Transpose-0
[09/07/2022-04:03:48] [V] [TRT] ShuffleShuffleFusion: Fusing Transpose-0 with Transpose-1
[09/07/2022-04:03:48] [V] [TRT] Running: ShuffleErasure on Transpose-0 + Transpose-1
[09/07/2022-04:03:48] [V] [TRT] Removing Transpose-0 + Transpose-1
[09/07/2022-04:03:48] [V] [TRT] After Myelin optimization: 1 layers
[09/07/2022-04:03:48] [V] [TRT] Applying ScaleNodes fusions.
[09/07/2022-04:03:48] [V] [TRT] After scale fusion: 1 layers
[09/07/2022-04:03:48] [V] [TRT] After dupe layer removal: 1 layers
[09/07/2022-04:03:48] [V] [TRT] After final dead-layer removal: 1 layers
[09/07/2022-04:03:48] [V] [TRT] After tensor merging: 1 layers
[09/07/2022-04:03:48] [V] [TRT] After vertical fusions: 1 layers
[09/07/2022-04:03:48] [V] [TRT] After dupe layer removal: 1 layers
[09/07/2022-04:03:48] [V] [TRT] After final dead-layer removal: 1 layers
[09/07/2022-04:03:48] [V] [TRT] After tensor merging: 1 layers
[09/07/2022-04:03:48] [V] [TRT] After slice removal: 1 layers
[09/07/2022-04:03:48] [V] [TRT] After concat removal: 1 layers
[09/07/2022-04:03:48] [V] [TRT] Trying to split Reshape and strided tensor
[09/07/2022-04:03:48] [V] [TRT] Graph construction and optimization completed in 0.000782951 seconds.
[09/07/2022-04:03:48] [V] [TRT] Using cublas as a tactic source
[09/07/2022-04:03:48] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +255, GPU +106, now: CPU 493, GPU 537 (MiB)
[09/07/2022-04:03:48] [V] [TRT] Using cuDNN as a tactic source
[09/07/2022-04:03:49] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +114, GPU +46, now: CPU 607, GPU 583 (MiB)
[09/07/2022-04:03:49] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[09/07/2022-04:03:49] [V] [TRT] Constructing optimization profile number 0 [1/1].
[09/07/2022-04:03:49] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[09/07/2022-04:03:49] [V] [TRT] =============== Computing reformatting costs
[09/07/2022-04:03:49] [V] [TRT] =============== Computing reformatting costs
[09/07/2022-04:03:49] [V] [TRT] =============== Computing costs for 
[09/07/2022-04:03:49] [V] [TRT] *************** Autotuning format combination: Float(262144,1024,1) -> Float(1024,1024,1) ***************
[09/07/2022-04:03:49] [V] [TRT] --------------- Timing Runner: ReduceSum (Reduce)
[09/07/2022-04:03:49] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.0162052
[09/07/2022-04:03:49] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0162052
[09/07/2022-04:03:49] [V] [TRT] Fastest Tactic: 0x0000000000000007 Time: 0.0162052
[09/07/2022-04:03:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000007
[09/07/2022-04:03:49] [V] [TRT] Formats and tactics selection completed in 0.00359721 seconds.
[09/07/2022-04:03:49] [V] [TRT] After reformat layers: 1 layers
[09/07/2022-04:03:49] [V] [TRT] Pre-optimized block assignment.
[09/07/2022-04:03:49] [V] [TRT] Block size 8505196544
[09/07/2022-04:03:49] [V] [TRT] Total Activation Memory: 8505196544
[09/07/2022-04:03:49] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[09/07/2022-04:03:49] [V] [TRT] Layer: ReduceSum Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[09/07/2022-04:03:49] [I] [TRT] Total Host Persistent Memory: 0
[09/07/2022-04:03:49] [I] [TRT] Total Device Persistent Memory: 0
[09/07/2022-04:03:49] [I] [TRT] Total Scratch Memory: 0
[09/07/2022-04:03:49] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 4 MiB
[09/07/2022-04:03:49] [V] [TRT] Optimized block assignment.
[09/07/2022-04:03:49] [I] [TRT] Total Activation Memory: 0
[09/07/2022-04:03:49] [V] [TRT] Disabling unused tactic source: CUDNN
[09/07/2022-04:03:49] [V] [TRT] Disabling unused tactic source: CUBLAS, CUBLAS_LT
[09/07/2022-04:03:49] [V] [TRT] Disabling unused tactic source: EDGE_MASK_CONVOLUTIONS
[09/07/2022-04:03:49] [V] [TRT] Engine generation completed in 0.306012 seconds.
[09/07/2022-04:03:49] [V] [TRT] Engine Layer Information:
Layer(Reduce): ReduceSum, Tactic: 0x0000000000000007, tensor0[Float(1,256,1024)] -> tensor1[Float(1,1,1024)]
[09/07/2022-04:03:49] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[09/07/2022-04:03:49] [W] [TRT] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
[09/07/2022-04:03:49] [W] [TRT] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
[09/07/2022-04:03:49] [I] Engine built in 1.09416 sec.
[09/07/2022-04:03:49] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 601, GPU 565 (MiB)
[09/07/2022-04:03:49] [I] [TRT] Loaded engine size: 0 MiB
[09/07/2022-04:03:49] [V] [TRT] Deserialization required 286 microseconds.
[09/07/2022-04:03:49] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[09/07/2022-04:03:49] [I] Engine deserialized in 0.000542861 sec.
[09/07/2022-04:03:49] [V] [TRT] Total per-runner device persistent memory is 0
[09/07/2022-04:03:49] [V] [TRT] Total per-runner host persistent memory is 0
[09/07/2022-04:03:49] [V] [TRT] Allocated activation device memory of size 0
[09/07/2022-04:03:49] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[09/07/2022-04:03:49] [I] Using random values for input tensor0
[09/07/2022-04:03:49] [I] Created input binding for tensor0 with dimensions 1x256x1024
[09/07/2022-04:03:49] [I] Using random values for output tensor1
[09/07/2022-04:03:49] [I] Created output binding for tensor1 with dimensions 1x1x1024
[09/07/2022-04:03:49] [I] Starting inference
[09/07/2022-04:03:52] [I] Warmup completed 10676 queries over 200 ms
[09/07/2022-04:03:52] [I] Timing trace has 160585 queries over 3.00003 s
[09/07/2022-04:03:52] [I] 
[09/07/2022-04:03:52] [I] === Trace details ===
[09/07/2022-04:03:52] [I] Trace averages of 10 runs:
[09/07/2022-04:03:52] [I] 
[09/07/2022-04:03:52] [I] === Performance summary ===
[09/07/2022-04:03:52] [I] Throughput: 53527.7 qps
[09/07/2022-04:03:52] [I] Latency: min = 0.0163574 ms, max = 0.138184 ms, mean = 0.0171717 ms, median = 0.017334 ms, percentile(99%) = 0.0175781 ms
[09/07/2022-04:03:52] [I] Enqueue Time: min = 0.000732422 ms, max = 0.0144043 ms, mean = 0.00109979 ms, median = 0.000976562 ms, percentile(99%) = 0.00195312 ms
[09/07/2022-04:03:52] [I] H2D Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(99%) = 0 ms
[09/07/2022-04:03:52] [I] GPU Compute Time: min = 0.0163574 ms, max = 0.138184 ms, mean = 0.0171717 ms, median = 0.017334 ms, percentile(99%) = 0.0175781 ms
[09/07/2022-04:03:52] [I] D2H Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(99%) = 0 ms
[09/07/2022-04:03:52] [I] Total Host Walltime: 3.00003 s
[09/07/2022-04:03:52] [I] Total GPU Compute Time: 2.75752 s
[09/07/2022-04:03:52] [W] * GPU compute time is unstable, with coefficient of variance = 4.73685%.
[09/07/2022-04:03:52] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.
[09/07/2022-04:03:52] [I] Explanations of the performance metrics are printed in the verbose logs.
[09/07/2022-04:03:52] [V] 
[09/07/2022-04:03:52] [V] === Explanations of the performance metrics ===
[09/07/2022-04:03:52] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[09/07/2022-04:03:52] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[09/07/2022-04:03:52] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[09/07/2022-04:03:52] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[09/07/2022-04:03:52] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[09/07/2022-04:03:52] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[09/07/2022-04:03:52] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[09/07/2022-04:03:52] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[09/07/2022-04:03:52] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8401] # trtexec --onnx=model-1.onnx --verbose --useCudaGraph --noDataTransfers --minShapes=tensor0:1x256x1024 --optShapes=tensor0:1x256x1024 --maxShapes=tensor0:1x256x1024 --shapes=tensor0:1x256x1024
&&&& RUNNING TensorRT.trtexec [TensorRT v8401] # trtexec --onnx=model-2.onnx --verbose --useCudaGraph --noDataTransfers --minShapes=tensor0:1x256x1024 --optShapes=tensor0:1x256x1024 --maxShapes=tensor0:1x256x1024 --shapes=tensor0:1x256x1024
[09/07/2022-04:03:52] [I] === Model Options ===
[09/07/2022-04:03:52] [I] Format: ONNX
[09/07/2022-04:03:52] [I] Model: model-2.onnx
[09/07/2022-04:03:52] [I] Output:
[09/07/2022-04:03:52] [I] === Build Options ===
[09/07/2022-04:03:52] [I] Max batch: explicit batch
[09/07/2022-04:03:52] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[09/07/2022-04:03:52] [I] minTiming: 1
[09/07/2022-04:03:52] [I] avgTiming: 8
[09/07/2022-04:03:52] [I] Precision: FP32
[09/07/2022-04:03:52] [I] LayerPrecisions: 
[09/07/2022-04:03:52] [I] Calibration: 
[09/07/2022-04:03:52] [I] Refit: Disabled
[09/07/2022-04:03:52] [I] Sparsity: Disabled
[09/07/2022-04:03:52] [I] Safe mode: Disabled
[09/07/2022-04:03:52] [I] DirectIO mode: Disabled
[09/07/2022-04:03:52] [I] Restricted mode: Disabled
[09/07/2022-04:03:52] [I] Build only: Disabled
[09/07/2022-04:03:52] [I] Save engine: 
[09/07/2022-04:03:52] [I] Load engine: 
[09/07/2022-04:03:52] [I] Profiling verbosity: 0
[09/07/2022-04:03:52] [I] Tactic sources: Using default tactic sources
[09/07/2022-04:03:52] [I] timingCacheMode: local
[09/07/2022-04:03:52] [I] timingCacheFile: 
[09/07/2022-04:03:52] [I] Input(s)s format: fp32:CHW
[09/07/2022-04:03:52] [I] Output(s)s format: fp32:CHW
[09/07/2022-04:03:52] [I] Input build shape: tensor0=1x256x1024+1x256x1024+1x256x1024
[09/07/2022-04:03:52] [I] Input calibration shapes: model
[09/07/2022-04:03:52] [I] === System Options ===
[09/07/2022-04:03:52] [I] Device: 0
[09/07/2022-04:03:52] [I] DLACore: 
[09/07/2022-04:03:52] [I] Plugins:
[09/07/2022-04:03:52] [I] === Inference Options ===
[09/07/2022-04:03:52] [I] Batch: Explicit
[09/07/2022-04:03:52] [I] Input inference shape: tensor0=1x256x1024
[09/07/2022-04:03:52] [I] Iterations: 10
[09/07/2022-04:03:52] [I] Duration: 3s (+ 200ms warm up)
[09/07/2022-04:03:52] [I] Sleep time: 0ms
[09/07/2022-04:03:52] [I] Idle time: 0ms
[09/07/2022-04:03:52] [I] Streams: 1
[09/07/2022-04:03:52] [I] ExposeDMA: Disabled
[09/07/2022-04:03:52] [I] Data transfers: Disabled
[09/07/2022-04:03:52] [I] Spin-wait: Disabled
[09/07/2022-04:03:52] [I] Multithreading: Disabled
[09/07/2022-04:03:52] [I] CUDA Graph: Enabled
[09/07/2022-04:03:52] [I] Separate profiling: Disabled
[09/07/2022-04:03:52] [I] Time Deserialize: Disabled
[09/07/2022-04:03:52] [I] Time Refit: Disabled
[09/07/2022-04:03:52] [I] Inputs:
[09/07/2022-04:03:52] [I] === Reporting Options ===
[09/07/2022-04:03:52] [I] Verbose: Enabled
[09/07/2022-04:03:52] [I] Averages: 10 inferences
[09/07/2022-04:03:52] [I] Percentile: 99
[09/07/2022-04:03:52] [I] Dump refittable layers:Disabled
[09/07/2022-04:03:52] [I] Dump output: Disabled
[09/07/2022-04:03:52] [I] Profile: Disabled
[09/07/2022-04:03:52] [I] Export timing to JSON file: 
[09/07/2022-04:03:52] [I] Export output to JSON file: 
[09/07/2022-04:03:52] [I] Export profile to JSON file: 
[09/07/2022-04:03:52] [I] 
[09/07/2022-04:03:52] [I] === Device Information ===
[09/07/2022-04:03:52] [I] Selected Device: NVIDIA GeForce GTX 1070
[09/07/2022-04:03:52] [I] Compute Capability: 6.1
[09/07/2022-04:03:52] [I] SMs: 16
[09/07/2022-04:03:52] [I] Compute Clock Rate: 1.645 GHz
[09/07/2022-04:03:52] [I] Device Global Memory: 8111 MiB
[09/07/2022-04:03:52] [I] Shared Memory per SM: 96 KiB
[09/07/2022-04:03:52] [I] Memory Bus Width: 256 bits (ECC disabled)
[09/07/2022-04:03:52] [I] Memory Clock Rate: 4.004 GHz
[09/07/2022-04:03:52] [I] 
[09/07/2022-04:03:52] [I] TensorRT version: 8.4.1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::Proposal version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::Split version 1
[09/07/2022-04:03:52] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[09/07/2022-04:03:52] [I] [TRT] [MemUsageChange] Init CUDA: CPU +194, GPU +0, now: CPU 202, GPU 425 (MiB)
[09/07/2022-04:03:53] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +6, GPU +2, now: CPU 228, GPU 427 (MiB)
[09/07/2022-04:03:53] [I] Start parsing network model
[09/07/2022-04:03:53] [I] [TRT] ----------------------------------------------------------------
[09/07/2022-04:03:53] [I] [TRT] Input filename:   model-2.onnx
[09/07/2022-04:03:53] [I] [TRT] ONNX IR version:  0.0.8
[09/07/2022-04:03:53] [I] [TRT] Opset version:    13
[09/07/2022-04:03:53] [I] [TRT] Producer name:    
[09/07/2022-04:03:53] [I] [TRT] Producer version: 
[09/07/2022-04:03:53] [I] [TRT] Domain:           
[09/07/2022-04:03:53] [I] [TRT] Model version:    0
[09/07/2022-04:03:53] [I] [TRT] Doc string:       
[09/07/2022-04:03:53] [I] [TRT] ----------------------------------------------------------------
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::Split version 1
[09/07/2022-04:03:53] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[09/07/2022-04:03:53] [V] [TRT] Adding network input: tensor0 with dtype: float32, dimensions: (-1, 256, -1)
[09/07/2022-04:03:53] [V] [TRT] Registering tensor: tensor0 for ONNX tensor: tensor0
[09/07/2022-04:03:53] [V] [TRT] Importing initializer: constantM1
[09/07/2022-04:03:53] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:367: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[09/07/2022-04:03:53] [V] [TRT] Parsing node: Transpose-0 [Transpose]
[09/07/2022-04:03:53] [V] [TRT] Searching for input: tensor0
[09/07/2022-04:03:53] [V] [TRT] Transpose-0 [Transpose] inputs: [tensor0 -> (-1, 256, -1)[FLOAT]], 
[09/07/2022-04:03:53] [V] [TRT] Registering layer: Transpose-0 for ONNX node: Transpose-0
[09/07/2022-04:03:53] [V] [TRT] Registering tensor: tensor2 for ONNX tensor: tensor2
[09/07/2022-04:03:53] [V] [TRT] Transpose-0 [Transpose] outputs: [tensor2 -> (-1, -1, 256)[FLOAT]], 
[09/07/2022-04:03:53] [V] [TRT] Parsing node: Identity-0 [Identity]
[09/07/2022-04:03:53] [V] [TRT] Searching for input: tensor2
[09/07/2022-04:03:53] [V] [TRT] Identity-0 [Identity] inputs: [tensor2 -> (-1, -1, 256)[FLOAT]], 
[09/07/2022-04:03:53] [V] [TRT] Registering layer: Identity-0 for ONNX node: Identity-0
[09/07/2022-04:03:53] [V] [TRT] Registering tensor: tensor3 for ONNX tensor: tensor3
[09/07/2022-04:03:53] [V] [TRT] Identity-0 [Identity] outputs: [tensor3 -> (-1, -1, 256)[FLOAT]], 
[09/07/2022-04:03:53] [V] [TRT] Parsing node: ReduceSum [ReduceSum]
[09/07/2022-04:03:53] [V] [TRT] Searching for input: tensor3
[09/07/2022-04:03:53] [V] [TRT] Searching for input: constantM1
[09/07/2022-04:03:53] [V] [TRT] ReduceSum [ReduceSum] inputs: [tensor3 -> (-1, -1, 256)[FLOAT]], [constantM1 -> (1)[INT32]], 
[09/07/2022-04:03:53] [V] [TRT] Registering layer: ReduceSum for ONNX node: ReduceSum
[09/07/2022-04:03:53] [V] [TRT] Registering tensor: tensor4 for ONNX tensor: tensor4
[09/07/2022-04:03:53] [V] [TRT] ReduceSum [ReduceSum] outputs: [tensor4 -> (-1, -1, 1)[FLOAT]], 
[09/07/2022-04:03:53] [V] [TRT] Parsing node: Transpose-1 [Transpose]
[09/07/2022-04:03:53] [V] [TRT] Searching for input: tensor4
[09/07/2022-04:03:53] [V] [TRT] Transpose-1 [Transpose] inputs: [tensor4 -> (-1, -1, 1)[FLOAT]], 
[09/07/2022-04:03:53] [V] [TRT] Registering layer: Transpose-1 for ONNX node: Transpose-1
[09/07/2022-04:03:53] [V] [TRT] Registering tensor: tensor1_0 for ONNX tensor: tensor1
[09/07/2022-04:03:53] [V] [TRT] Transpose-1 [Transpose] outputs: [tensor1 -> (-1, 1, -1)[FLOAT]], 
[09/07/2022-04:03:53] [V] [TRT] Marking tensor1_0 as output: tensor1
[09/07/2022-04:03:53] [I] Finish parsing network model
[09/07/2022-04:03:53] [V] [TRT] Applying generic optimizations to the graph for inference.
[09/07/2022-04:03:53] [V] [TRT] Original: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After dead-layer removal: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After Myelin optimization: 4 layers
[09/07/2022-04:03:53] [V] [TRT] Applying ScaleNodes fusions.
[09/07/2022-04:03:53] [V] [TRT] After scale fusion: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After dupe layer removal: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After final dead-layer removal: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After tensor merging: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After vertical fusions: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After dupe layer removal: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After final dead-layer removal: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After tensor merging: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After slice removal: 4 layers
[09/07/2022-04:03:53] [V] [TRT] After concat removal: 4 layers
[09/07/2022-04:03:53] [V] [TRT] Trying to split Reshape and strided tensor
[09/07/2022-04:03:53] [V] [TRT] Graph construction and optimization completed in 0.00172442 seconds.
[09/07/2022-04:03:53] [V] [TRT] Using cublas as a tactic source
[09/07/2022-04:03:53] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +256, GPU +106, now: CPU 494, GPU 537 (MiB)
[09/07/2022-04:03:53] [V] [TRT] Using cuDNN as a tactic source
[09/07/2022-04:03:53] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +113, GPU +46, now: CPU 607, GPU 583 (MiB)
[09/07/2022-04:03:53] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[09/07/2022-04:03:53] [V] [TRT] Constructing optimization profile number 0 [1/1].
[09/07/2022-04:03:53] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[09/07/2022-04:03:53] [V] [TRT] =============== Computing reformatting costs
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(262144,1024,1) -> Float(1,1024,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor0 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0142196
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0146139
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0138307
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0138307
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(262144,1024,1) -> Float(262144:32,1024,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor0 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.15789
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.667209
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.14838
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.667209
[09/07/2022-04:03:53] [V] [TRT] =============== Computing reformatting costs
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(262144,256,1) -> Float(1,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor2 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0138838
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0234893
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.013711
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.013711
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(262144,256,1) -> Float(262144:32,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor2 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.14107
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.666331
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.14838
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.666331
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1,256,1) -> Float(262144,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor2 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0106893
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0249173
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0104803
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0104803
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1,256,1) -> Float(262144:32,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor2 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.14048
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.621723
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.1712
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.621723
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(262144:32,256,1) -> Float(262144,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor2 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0475429
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.644974
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0477867
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0475429
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(262144:32,256,1) -> Float(1,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor2 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0476404
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.644242
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0475909
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0475909
[09/07/2022-04:03:53] [V] [TRT] =============== Computing reformatting costs
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1,256,1) -> Float(262144,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(262144:32,256,1) -> Float(262144,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] =============== Computing reformatting costs
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1,1,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> tensor4) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00733623
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0230981
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00743771
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00733623
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1024:32,1,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> tensor4) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0112362
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0228147
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0111072
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0111072
[09/07/2022-04:03:53] [V] [TRT] =============== Computing reformatting costs
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1,1,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor4 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00699864
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0223125
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00720777
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00699864
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1024,1,1) -> Float(1024:32,1,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor4 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0115791
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0405943
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0122149
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0115791
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1,1,1) -> Float(1024,1,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor4 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00711053
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0220878
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00745714
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.00711053
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1,1,1) -> Float(1024:32,1,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor4 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0111008
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0228689
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.011174
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0111008
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1024:32,1,1) -> Float(1024,1,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor4 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.007264
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0170169
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00528343
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00528343
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1024:32,1,1) -> Float(1,1,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(tensor4 -> <out>) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00501754
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0139703
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00403924
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00403924
[09/07/2022-04:03:53] [V] [TRT] =============== Computing reformatting costs
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1,1024,1) -> Float(1024,1024,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> tensor1) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00380162
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.010162
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00341682
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00341682
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning Reformat: Float(1024:32,1024,1) -> Float(1024,1024,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> tensor1) (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00299629
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0131524
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00295799
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00295799
[09/07/2022-04:03:53] [V] [TRT] =============== Computing costs for 
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning format combination: Float(262144,1024,1) -> Float(262144,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Transpose-0 (Shuffle)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0127756
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0221355
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0127756
[09/07/2022-04:03:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning format combination: Float(1,1024,1) -> Float(1,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Transpose-0 (Shuffle)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0128362
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0274362
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0128362
[09/07/2022-04:03:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning format combination: Float(262144:32,1024,1) -> Float(262144:32,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Transpose-0 (Shuffle)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 2.47369
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.724946
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000001 Time: 0.724946
[09/07/2022-04:03:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001
[09/07/2022-04:03:53] [V] [TRT] =============== Computing costs for 
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning format combination: Float(262144,256,1) -> Float(262144,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Identity-0 (Cast)
[09/07/2022-04:03:53] [V] [TRT] Cast has no valid tactics for this config, skipping
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Identity-0 (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00621436
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.012997
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00476181
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00476181
[09/07/2022-04:03:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning format combination: Float(262144,256,1) -> Float(1,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Identity-0 (Cast)
[09/07/2022-04:03:53] [V] [TRT] Cast has no valid tactics for this config, skipping
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Identity-0 (Reformat)
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0138307
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0144489
[09/07/2022-04:03:53] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0137775
[09/07/2022-04:03:53] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0137775
[09/07/2022-04:03:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[09/07/2022-04:03:53] [V] [TRT] *************** Autotuning format combination: Float(262144,256,1) -> Float(262144:32,256,1) ***************
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Identity-0 (Cast)
[09/07/2022-04:03:53] [V] [TRT] Cast has no valid tactics for this config, skipping
[09/07/2022-04:03:53] [V] [TRT] --------------- Timing Runner: Identity-0 (Reformat)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.15226
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.671159
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.27053
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.671159
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[09/07/2022-04:03:54] [V] [TRT] *************** Autotuning format combination: Float(1,256,1) -> Float(262144,256,1) ***************
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Cast)
[09/07/2022-04:03:54] [V] [TRT] Cast has no valid tactics for this config, skipping
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Reformat)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0108878
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0262827
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0106475
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0106475
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[09/07/2022-04:03:54] [V] [TRT] *************** Autotuning format combination: Float(1,256,1) -> Float(1,256,1) ***************
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Cast)
[09/07/2022-04:03:54] [V] [TRT] Cast has no valid tactics for this config, skipping
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Reformat)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0136977
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0265752
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0137376
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0136977
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[09/07/2022-04:03:54] [V] [TRT] *************** Autotuning format combination: Float(1,256,1) -> Float(262144:32,256,1) ***************
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Cast)
[09/07/2022-04:03:54] [V] [TRT] Cast has no valid tactics for this config, skipping
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Reformat)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 5.126
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.625518
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 5.13477
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.625518
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[09/07/2022-04:03:54] [V] [TRT] *************** Autotuning format combination: Float(262144:32,256,1) -> Float(262144,256,1) ***************
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Cast)
[09/07/2022-04:03:54] [V] [TRT] Cast has no valid tactics for this config, skipping
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Reformat)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0476891
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.646583
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0475063
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0475063
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x0000000000000000
[09/07/2022-04:03:54] [V] [TRT] *************** Autotuning format combination: Float(262144:32,256,1) -> Float(1,256,1) ***************
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Cast)
[09/07/2022-04:03:54] [V] [TRT] Cast has no valid tactics for this config, skipping
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Reformat)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0477029
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.64629
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0477867
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0477029
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003e8
[09/07/2022-04:03:54] [V] [TRT] *************** Autotuning format combination: Float(262144:32,256,1) -> Float(262144:32,256,1) ***************
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Cast)
[09/07/2022-04:03:54] [V] [TRT] Cast has no valid tactics for this config, skipping
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Identity-0 (Reformat)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003e8 Time: 4.89999
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.634002
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 4.91915
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.634002
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[09/07/2022-04:03:54] [V] [TRT] =============== Computing costs for 
[09/07/2022-04:03:54] [V] [TRT] *************** Autotuning format combination: Float(262144,256,1) -> Float(1024,1,1) ***************
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: ReduceSum (Reduce)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0374491
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000002 Time: 0.0078886
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000003 Time: 0.0128366
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000004 Time: 0.0125265
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000007 Time: 0.019948
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000008 Time: 0.0199131
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x0000000000000002 Time: 0.0078886
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reduce Tactic: 0x0000000000000002
[09/07/2022-04:03:54] [V] [TRT] =============== Computing costs for 
[09/07/2022-04:03:54] [V] [TRT] *************** Autotuning format combination: Float(1024,1,1) -> Float(1024,1024,1) ***************
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Transpose-1 (Shuffle)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00808635
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0204826
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00808635
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[09/07/2022-04:03:54] [V] [TRT] *************** Autotuning format combination: Float(1,1,1) -> Float(1,1024,1) ***************
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Transpose-1 (Shuffle)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00797587
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0214073
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00797587
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[09/07/2022-04:03:54] [V] [TRT] *************** Autotuning format combination: Float(1024:32,1,1) -> Float(1024:32,1024,1) ***************
[09/07/2022-04:03:54] [V] [TRT] --------------- Timing Runner: Transpose-1 (Shuffle)
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00839238
[09/07/2022-04:03:54] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0246979
[09/07/2022-04:03:54] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00839238
[09/07/2022-04:03:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[09/07/2022-04:03:54] [V] [TRT] Formats and tactics selection completed in 0.753152 seconds.
[09/07/2022-04:03:54] [V] [TRT] After reformat layers: 4 layers
[09/07/2022-04:03:54] [V] [TRT] Pre-optimized block assignment.
[09/07/2022-04:03:54] [V] [TRT] Block size 1048576
[09/07/2022-04:03:54] [V] [TRT] Block size 4
[09/07/2022-04:03:54] [V] [TRT] Block size 4
[09/07/2022-04:03:54] [V] [TRT] Block size 8505196544
[09/07/2022-04:03:54] [V] [TRT] Total Activation Memory: 8506245128
[09/07/2022-04:03:54] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[09/07/2022-04:03:54] [V] [TRT] Layer: Transpose-0 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[09/07/2022-04:03:54] [V] [TRT] Layer: Identity-0 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[09/07/2022-04:03:54] [V] [TRT] Layer: ReduceSum Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[09/07/2022-04:03:54] [V] [TRT] Layer: Transpose-1 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[09/07/2022-04:03:54] [I] [TRT] Total Host Persistent Memory: 0
[09/07/2022-04:03:54] [I] [TRT] Total Device Persistent Memory: 0
[09/07/2022-04:03:54] [I] [TRT] Total Scratch Memory: 0
[09/07/2022-04:03:54] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 64 MiB
[09/07/2022-04:03:54] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.018918ms to assign 3 blocks to 3 nodes requiring 1048584 bytes.
[09/07/2022-04:03:54] [V] [TRT] Optimized block assignment.
[09/07/2022-04:03:54] [V] [TRT] Block size 1048576
[09/07/2022-04:03:54] [V] [TRT] Block size 4
[09/07/2022-04:03:54] [V] [TRT] Block size 4
[09/07/2022-04:03:54] [I] [TRT] Total Activation Memory: 1048584
[09/07/2022-04:03:54] [V] [TRT] Disabling unused tactic source: CUDNN
[09/07/2022-04:03:54] [V] [TRT] Disabling unused tactic source: CUBLAS, CUBLAS_LT
[09/07/2022-04:03:54] [V] [TRT] Disabling unused tactic source: EDGE_MASK_CONVOLUTIONS
[09/07/2022-04:03:54] [V] [TRT] Engine generation completed in 1.05763 seconds.
[09/07/2022-04:03:54] [V] [TRT] Deleting timing cache: 24 entries, served 2 hits since creation.
[09/07/2022-04:03:54] [V] [TRT] Engine Layer Information:
Layer(Shuffle): Transpose-0, Tactic: 0x0000000000000000, tensor0[Float(1,256,1024)] -> tensor2[Float(1,1024,256)]
Layer(NoOp): Identity-0, Tactic: 0x0000000000000000, tensor2[Float(1,1024,256)] -> tensor3[Float(1,1024,256)]
Layer(Reduce): ReduceSum, Tactic: 0x0000000000000002, tensor3[Float(1,1024,256)] -> tensor4[Float(1,1024,1)]
Layer(NoOp): Transpose-1, Tactic: 0x0000000000000000, tensor4[Float(1,1024,1)] -> tensor1[Float(1,1,1024)]
[09/07/2022-04:03:54] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[09/07/2022-04:03:54] [W] [TRT] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
[09/07/2022-04:03:54] [W] [TRT] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
[09/07/2022-04:03:54] [I] Engine built in 1.85076 sec.
[09/07/2022-04:03:54] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 601, GPU 565 (MiB)
[09/07/2022-04:03:54] [I] [TRT] Loaded engine size: 0 MiB
[09/07/2022-04:03:54] [V] [TRT] Deserialization required 1129 microseconds.
[09/07/2022-04:03:54] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[09/07/2022-04:03:54] [I] Engine deserialized in 0.00202239 sec.
[09/07/2022-04:03:54] [V] [TRT] Total per-runner device persistent memory is 0
[09/07/2022-04:03:54] [V] [TRT] Total per-runner host persistent memory is 0
[09/07/2022-04:03:54] [V] [TRT] Allocated activation device memory of size 1049600
[09/07/2022-04:03:54] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)
[09/07/2022-04:03:54] [I] Using random values for input tensor0
[09/07/2022-04:03:54] [I] Created input binding for tensor0 with dimensions 1x256x1024
[09/07/2022-04:03:54] [I] Using random values for output tensor1
[09/07/2022-04:03:54] [I] Created output binding for tensor1 with dimensions 1x1x1024
[09/07/2022-04:03:54] [I] Starting inference
[09/07/2022-04:03:57] [I] Warmup completed 9236 queries over 200 ms
[09/07/2022-04:03:57] [I] Timing trace has 146375 queries over 3.00003 s
[09/07/2022-04:03:57] [I] 
[09/07/2022-04:03:57] [I] === Trace details ===
[09/07/2022-04:03:57] [I] Trace averages of 10 runs:
[09/07/2022-04:03:57] [I] 
[09/07/2022-04:03:57] [I] === Performance summary ===
[09/07/2022-04:03:57] [I] Throughput: 48791.2 qps
[09/07/2022-04:03:57] [I] Latency: min = 0.0163574 ms, max = 0.0910645 ms, mean = 0.0176269 ms, median = 0.0174255 ms, percentile(99%) = 0.0185547 ms
[09/07/2022-04:03:57] [I] Enqueue Time: min = 0.000732422 ms, max = 0.0327148 ms, mean = 0.00117318 ms, median = 0.00109863 ms, percentile(99%) = 0.00195312 ms
[09/07/2022-04:03:57] [I] H2D Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(99%) = 0 ms
[09/07/2022-04:03:57] [I] GPU Compute Time: min = 0.0163574 ms, max = 0.0910645 ms, mean = 0.0176269 ms, median = 0.0174255 ms, percentile(99%) = 0.0185547 ms
[09/07/2022-04:03:57] [I] D2H Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(99%) = 0 ms
[09/07/2022-04:03:57] [I] Total Host Walltime: 3.00003 s
[09/07/2022-04:03:57] [I] Total GPU Compute Time: 2.58013 s
[09/07/2022-04:03:57] [W] * GPU compute time is unstable, with coefficient of variance = 4.91307%.
[09/07/2022-04:03:57] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.
[09/07/2022-04:03:57] [I] Explanations of the performance metrics are printed in the verbose logs.
[09/07/2022-04:03:57] [V] 
[09/07/2022-04:03:57] [V] === Explanations of the performance metrics ===
[09/07/2022-04:03:57] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[09/07/2022-04:03:57] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[09/07/2022-04:03:57] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[09/07/2022-04:03:57] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[09/07/2022-04:03:57] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[09/07/2022-04:03:57] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[09/07/2022-04:03:57] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[09/07/2022-04:03:57] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[09/07/2022-04:03:57] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8401] # trtexec --onnx=model-2.onnx --verbose --useCudaGraph --noDataTransfers --minShapes=tensor0:1x256x1024 --optShapes=tensor0:1x256x1024 --maxShapes=tensor0:1x256x1024 --shapes=tensor0:1x256x1024
Succeeded building model-0.onnx!
Succeeded building model-1.onnx!
Succeeded building model-2.onnx!
